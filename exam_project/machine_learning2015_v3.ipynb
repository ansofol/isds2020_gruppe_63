{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from shapely.geometry import Point, Polygon\n",
    "import geopandas as gpd\n",
    "from shapely.ops import nearest_points\n",
    "import pyproj\n",
    "\n",
    "import warnings\n",
    "from sklearn.exceptions import ConvergenceWarning\n",
    "warnings.filterwarnings(action='ignore', category=ConvergenceWarning)\n",
    "\n",
    "from sklearn.metrics import mean_squared_error as mse\n",
    "from sklearn.model_selection import train_test_split, KFold, LeaveOneOut, GridSearchCV\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import PolynomialFeatures, StandardScaler\n",
    "from sklearn.linear_model import Lasso, Ridge, LinearRegression, ElasticNet\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "cwd =os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "background_data = pd.read_csv('final_data2015.csv').drop(columns='geometry')\n",
    "geodata = gpd.read_file(cwd+'\\scrape_geodata\\geodata\\dagi_10m_nohist_l1.afstemningsomraade\\\\afstemningsomraade.shp', driver = 'ESRI Shapefile')\n",
    "geodata = geodata[['objectid', 'geometry']]\n",
    "geodata['objectid'] = geodata['objectid'].astype(int)\n",
    "final_gdf = geodata.merge(background_data, on='objectid', how='right')\n",
    "\n",
    "final_gdf['left_share_norm']=final_gdf['left_share']/(final_gdf['left_share']+final_gdf['right_share'])\n",
    "final_gdf['pop_density_log']=np.log(final_gdf['pop_density'])\n",
    "final_gdf['disindk_log']=np.log(final_gdf['disindk'])\n",
    "final_gdf['salgspris_log']=np.log(final_gdf['salgspris'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = final_gdf[['karakter', 'salgspris_log', 'kriminelitet', 'lavindk',\n",
    "               'langledig', 'skilsmisser', 'andel_indv', 'pop_density_log',\n",
    "               'disindk_log']]\n",
    "y = final_gdf['left_share_norm']\n",
    "\n",
    "# splitting into development (2/3) and test data (1/3)\n",
    "X_dev, X_test, y_dev, y_test = train_test_split(X, y, test_size=1/3, random_state=1)\n",
    "# splitting development into train (1/3) and validation (1/3)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_dev, y_dev, test_size=1/2, random_state=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear regression model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "0.004162525363956261"
     },
     "metadata": {},
     "execution_count": 34
    }
   ],
   "source": [
    "pipe_lr = make_pipeline(PolynomialFeatures(include_bias=True), \n",
    "                           StandardScaler(),\n",
    "                            LinearRegression())\n",
    "pipe_lr.fit(X_train, y_train)\n",
    "y_pred = pipe_lr.predict(X_val)\n",
    "mse(y_pred, y_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lasso model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Optimal lambda: 4.328761281083062e-05\nValidation MSE: 0.00392724\n"
    }
   ],
   "source": [
    "# splitting into development (2/3) and test data (1/3)\n",
    "X_dev, X_test, y_dev, y_test = train_test_split(X, y, test_size=1/3, random_state=1)\n",
    "# splitting development into train (1/3) and validation (1/3)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_dev, y_dev, test_size=1/2, random_state=1)\n",
    "\n",
    "perform = []\n",
    "lambdas = np.logspace(-6, -4, 100)\n",
    "for lambda_ in lambdas:\n",
    "    pipe_lasso = make_pipeline(PolynomialFeatures(include_bias=True), \n",
    "                               StandardScaler(),\n",
    "                               Lasso(alpha=lambda_, random_state=1, fit_intercept=True))\n",
    "    pipe_lasso.fit(X_train, y_train)\n",
    "    y_pred = pipe_lasso.predict(X_val)\n",
    "    perform.append(mse(y_pred, y_val))\n",
    "    \n",
    "hyperparam_perform = pd.Series(perform,index=lambdas)\n",
    "optimal = hyperparam_perform.nsmallest(1)\n",
    "print('Optimal lambda:', optimal.index[0])\n",
    "print('Validation MSE: %.8f' % optimal.values[0])\n",
    "lambda_lasso = optimal.index[0] # Sofie Add on"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "\"plot_df = pd.DataFrame(hyperparam_perform).reset_index()\\nplot_df['index'] = np.log10(plot_df['index'])\\nplot_df['x_axis'] = plot_df['index']\\nsns.lineplot(data=plot_df, x='x_axis', y=0)\""
     },
     "metadata": {},
     "execution_count": 36
    }
   ],
   "source": [
    "\"\"\"plot_df = pd.DataFrame(hyperparam_perform).reset_index()\n",
    "plot_df['index'] = np.log10(plot_df['index'])\n",
    "plot_df['x_axis'] = plot_df['index']\n",
    "sns.lineplot(data=plot_df, x='x_axis', y=0)\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Lasso MSE on test data: 0.00451162013648022\n"
    }
   ],
   "source": [
    "# Define preferable model\n",
    "pipe_lasso = make_pipeline(PolynomialFeatures(include_bias = True),\n",
    "                           StandardScaler(),\n",
    "                           Lasso(alpha = lambda_lasso, random_state = 1, fit_intercept = True))\n",
    "\n",
    "pipe_lasso.fit(X_dev, y_dev) \n",
    "\"\"\"\n",
    "errors = pipe_lasso.predict(X_test)-y_test\n",
    "error_gdf = final_gdf.merge(pd.DataFrame(errors), left_index=True, right_index=True, how='left')\n",
    "error_gdf.plot(column='left_share_norm_y', legend=True)\n",
    "\"\"\"\n",
    "print('Lasso MSE on test data:', mse(pipe_lasso.predict(X_test),y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ridge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Optimal lambda: 0.01\nValidation MSE: 0.00378513\n"
    }
   ],
   "source": [
    "# splitting into development (2/3) and test data (1/3)\n",
    "X_dev, X_test, y_dev, y_test = train_test_split(X, y, test_size=1/3, random_state=1)\n",
    "# splitting development into train (1/3) and validation (1/3)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_dev, y_dev, test_size=1/2, random_state=1)\n",
    "\n",
    "perform = []\n",
    "lambdas = np.logspace(-20, 4, 33)\n",
    "for lambda_ in lambdas:\n",
    "    pipe_ridge = make_pipeline(PolynomialFeatures(include_bias=True), \n",
    "                               StandardScaler(),\n",
    "                               Ridge(alpha=lambda_, random_state=1))\n",
    "    pipe_ridge.fit(X_train, y_train)\n",
    "    y_pred = pipe_ridge.predict(X_val)\n",
    "    perform.append(mse(y_pred, y_val))\n",
    "    \n",
    "hyperparam_perform = pd.Series(perform,index=lambdas)\n",
    "optimal = hyperparam_perform.nsmallest(1)    \n",
    "print('Optimal lambda:', optimal.index[0])\n",
    "print('Validation MSE: %.8f' % optimal.values[0])\n",
    "lambda_ridge = optimal.index[0] # Sofie Add on"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Ridge MSE on test data: 0.004365310981042533\n"
    }
   ],
   "source": [
    "#Sofie Add on\n",
    "pipe_ridge = make_pipeline(PolynomialFeatures(include_bias=True),\n",
    "                           StandardScaler(),\n",
    "                           Ridge(alpha = lambda_ridge, random_state=1))\n",
    "pipe_ridge.fit(X_dev,y_dev)\n",
    "\"\"\"\n",
    "errors = pipe_ridge.predict(X_test)-y_test\n",
    "error_gdf = final_gdf.merge(pd.DataFrame(errors), left_index=True, right_index=True, how='left')\n",
    "error_gdf.plot(column='left_share_norm_y', legend=True)\n",
    "\"\"\"\n",
    "\n",
    "print('Ridge MSE on test data:', mse(pipe_ridge.predict(X_test), y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lasso - cross-validation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# splitting into development (2/3) and test data (1/3)\n",
    "X_dev, X_test, y_dev, y_test = train_test_split(X, y, test_size=1/3, random_state=1)\n",
    "\n",
    "kfolds = KFold(n_splits=10)\n",
    "\n",
    "folds = list(kfolds.split(X_dev, y_dev))\n",
    "# outer loop: lambdas\n",
    "mselassoCV = []\n",
    "lambdas = np.logspace(-6, -1, 33)\n",
    "for lambda_ in lambdas:    \n",
    "    # inner loop: folds\n",
    "    mselassoCV_ = []    \n",
    "    for train_idx, val_idx in folds:        \n",
    "        # train model and compute MSE on test fold\n",
    "        pipe_lassoCV = make_pipeline(PolynomialFeatures(degree=2, include_bias=True),\n",
    "                                     StandardScaler(),\n",
    "                                     Lasso(alpha=lambda_, random_state=1))            \n",
    "        X_train, y_train = X_dev.values[train_idx], y_dev.values[train_idx]\n",
    "        X_val, y_val = X_dev.values[val_idx], y_dev.values[val_idx] \n",
    "        pipe_lassoCV.fit(X_train, y_train)        \n",
    "        mselassoCV_.append(mse(pipe_lassoCV.predict(X_val), y_val))    \n",
    "        \n",
    "    # store result    \n",
    "    mselassoCV.append(mselassoCV_) \n",
    "    \n",
    "# convert to DataFrame\n",
    "lambdalassoCV = pd.DataFrame(mselassoCV, index=lambdas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "optimal = lambdalassoCV.mean(axis = 1).nsmallest(1)\n",
    "\"\"\"\n",
    "plot_df = pd.DataFrame(lambdalassoCV).reset_index()\n",
    "plot_df['index'] = np.log10(plot_df['index'])\n",
    "plot_df['x_axis'] = plot_df['index']\n",
    "sns.lineplot(data=plot_df, x='x_axis', y=0)\n",
    "\"\"\"\n",
    "\n",
    "lambda_lassoCV = optimal.index[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Lasso CV MSE: 0.004517433489375399\n"
    }
   ],
   "source": [
    "# Sofie Add on\n",
    "pipe_lassoCV = make_pipeline(PolynomialFeatures(degree=2, include_bias=True),\n",
    "                                     StandardScaler(),\n",
    "                                     Lasso(alpha=lambda_lassoCV, random_state=1))\n",
    "\n",
    "pipe_lassoCV.fit(X_dev,y_dev)\n",
    "print('Lasso CV MSE:', mse(pipe_lassoCV.predict(X_test), y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ridge - cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# splitting into development (2/3) and test data (1/3)\n",
    "X_dev, X_test, y_dev, y_test = train_test_split(X, y, test_size=1/3, random_state=1)\n",
    "\n",
    "kfolds = KFold(n_splits=10)\n",
    "# kfolds = LeaveOneOut()\n",
    "\n",
    "folds = list(kfolds.split(X_dev, y_dev))\n",
    "# outer loop: lambdas\n",
    "mseridgeCV = []\n",
    "lambdas = np.logspace(-8, 0, 100)\n",
    "for lambda_ in lambdas:    \n",
    "    # inner loop: folds\n",
    "    mseridgeCV_ = []    \n",
    "    for train_idx, val_idx in folds:        \n",
    "        # train model and compute MSE on test fold\n",
    "        pipe_ridgeCV = make_pipeline(PolynomialFeatures(degree=2, include_bias=True),\n",
    "                                     StandardScaler(),\n",
    "                                     Ridge(alpha=lambda_, random_state=1))            \n",
    "        X_train, y_train = X_dev.values[train_idx], y_dev.values[train_idx]\n",
    "        X_val, y_val = X_dev.values[val_idx], y_dev.values[val_idx] \n",
    "        pipe_ridgeCV.fit(X_train, y_train)        \n",
    "        mseridgeCV_.append(mse(pipe_ridgeCV.predict(X_val), y_val))    \n",
    "        \n",
    "    # store result    \n",
    "    mseridgeCV.append(mseridgeCV_) \n",
    "    \n",
    "# convert to DataFrame\n",
    "lambdaridgeCV = pd.DataFrame(mseridgeCV, index=lambdas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "0.001233    0.004028\ndtype: float64\n"
    }
   ],
   "source": [
    "optimal = lambdaridgeCV.mean(axis=1).nsmallest(1) \n",
    "print(optimal)\n",
    "\"\"\"\n",
    "plot_df = pd.DataFrame(lambdaridgeCV).reset_index()\n",
    "plot_df['index'] = np.log10(plot_df['index'])\n",
    "plot_df['x_axis'] = plot_df['index']\n",
    "sns.lineplot(data=plot_df, x='x_axis', y=0)\n",
    "\"\"\"\n",
    "lambda_ridgeCV = optimal.index[0] # Sofie Add on"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Ridge CV MSE: 0.00436446379979942\n"
    }
   ],
   "source": [
    "# Define preferable modal\n",
    "pipe_ridgeCV = make_pipeline(PolynomialFeatures(),\n",
    "                             StandardScaler(),\n",
    "                             Ridge(alpha=lambda_ridgeCV, random_state=1))\n",
    "\n",
    "pipe_ridgeCV.fit(X_dev, y_dev)\n",
    "print('Ridge CV MSE:', mse(pipe_ridgeCV.predict(X_test),y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Elastic Net - cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compare performance\n",
    "models = {'LinReg': pipe_lr, 'Lasso': pipe_lasso, 'Lasso CV': pipe_lassoCV,\n",
    "         'Ridge': pipe_ridge, 'Ridge CV': pipe_ridgeCV,}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# splitting into development (2/3) and test data (1/3)\n",
    "X_dev, X_test, y_dev, y_test = train_test_split(X, y, test_size=1/3, random_state=1)\n",
    "\n",
    "pipe_el = make_pipeline(PolynomialFeatures(include_bias=True),StandardScaler(),ElasticNet(random_state=1))\n",
    "gs = GridSearchCV(estimator=pipe_el,\n",
    "                  param_grid = {'elasticnet__alpha':np.logspace(-6,2,40)*2,\n",
    "                              'elasticnet__l1_ratio':np.linspace(0,1,10)},\n",
    "                  scoring='neg_mean_squared_error',\n",
    "                  n_jobs=4,\n",
    "                  iid=False,\n",
    "                  cv=10)\n",
    "models['ElasticNetCV'] = gs.fit(X_dev, y_dev)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compare performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "VALIDATION PERFORMANCE\nFit on train, test on val\nLinReg 0.004163\nLasso 0.003927\nLasso CV 0.00394\nRidge 0.003785\nRidge CV 0.003804\nElasticNetCV 0.003969\n\nTEST PERFORMANCE 1\nFit on train, test on test\nLinReg 0.004557\nLasso 0.00464\nLasso CV 0.004662\nRidge 0.004505\nRidge CV 0.004528\nElasticNetCV 0.004714\n\nTEST PERFORMANCE 2\nFit on dev, test on test\nLinReg 0.004349\nLasso 0.004512\nLasso CV 0.004517\nRidge 0.004365\nRidge CV 0.004364\nElasticNetCV 0.004509\n"
    }
   ],
   "source": [
    "# splitting into development (2/3) and test data (1/3)\n",
    "X_dev, X_test, y_dev, y_test = train_test_split(X, y, test_size=1/3, random_state=1)\n",
    "# splitting development into train (1/3) and validation (1/3)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_dev, y_dev, test_size=1/2, random_state=1)\n",
    "\n",
    "print('Validation performance'.upper())\n",
    "print('Fit on train, test on val')\n",
    "for name, model in models.items():\n",
    "    model.fit(X_train, y_train)\n",
    "    score = mse(model.predict(X_val),y_val)\n",
    "    print(name, round(score, 6))\n",
    "\n",
    "print()\n",
    "print('Test performance 1'.upper())\n",
    "print('Fit on train, test on test')\n",
    "for name, model in models.items():\n",
    "    model.fit(X_train, y_train)\n",
    "    score = mse(model.predict(X_test), y_test)\n",
    "    print(name, round(score, 6))\n",
    "\n",
    "print()\n",
    "print('Test performance 2'.upper())\n",
    "print('Fit on dev, test on test')\n",
    "for name, model in models.items():\n",
    "    model.fit(X_dev, y_dev)\n",
    "    score = mse(model.predict(X_test), y_test)\n",
    "    print(name, round(score, 6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare on test and validation mse as well as correct prediction share.\n",
    "\n",
    "for model in models.values():\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "pred_lr = pipe_lr.predict(X_test)\n",
    "pred_lasso = pipe_lasso.predict(X_test)\n",
    "pred_lassoCV = pipe_lassoCV.predict(X_test)\n",
    "pred_ridge = pipe_ridge.predict(X_test)\n",
    "pred_ridgeCV = pipe_ridgeCV.predict(X_test)\n",
    "pred_el = gs.predict(X_test)\n",
    "\n",
    "models_test_df = pd.DataFrame({'LinReg': pred_lr, 'Lasso': pred_lasso, 'LassoCV':pred_lassoCV, 'Ridge': pred_ridge, 'RidgeCV': pred_ridgeCV, 'ElasticNet': pred_el, 'Left share': y_test})\n",
    "\n",
    "# dummy for left majority\n",
    "for model in models_test_df.columns:\n",
    "    models_test_df[model+'_majority'] = (models_test_df[model] >0.5)*1\n",
    "\n",
    "# correct prediction and test mse\n",
    "for model in models_test_df[['LinReg', 'Lasso', 'LassoCV', 'Ridge', 'RidgeCV', 'ElasticNet']]:\n",
    "    models_test_df[model+'_correct'] = (models_test_df[model+'_majority'] == models_test_df['Left share_majority'])*1\n",
    "\n",
    "    models_test_df[model+'_testMSE'] = mse(models_test_df[model], y_test)\n",
    "\n",
    "# validation mse\n",
    "for name, model in models.items():\n",
    "    model.fit(X_train, y_train)\n",
    "    models_test_df[name+'_valMSE'] = mse(model.predict(X_val), y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make table for report\n",
    "table = pd.DataFrame(models_test_df[['LinReg_correct', 'Lasso_correct', 'LassoCV_correct', 'Ridge_correct', 'RidgeCV_correct', 'ElasticNet_correct', 'LinReg_valMSE', 'Lasso_valMSE', 'Lasso CV_valMSE', 'Ridge_valMSE', 'Ridge CV_valMSE', 'ElasticNetCV_valMSE', 'LinReg_testMSE', 'Lasso_testMSE', 'LassoCV_testMSE', 'Ridge_testMSE', 'RidgeCV_testMSE', 'ElasticNet_testMSE' ]].mean())\n",
    "\n",
    "table['correct'] = table.index.str.contains('correct')*table[0]\n",
    "table['valMSE'] = table.index.str.contains('valMSE')*table[0]\n",
    "table['testMSE'] = table.index.str.contains('testMSE')*table[0]\n",
    "\n",
    "table['model'] = ['LinReg', 'Lasso', 'LassoCV', 'Ridge', 'RidgeCV', 'ElasticNetCV']*3\n",
    "table = table.drop(0, axis = 1)\n",
    "table = table.reset_index(drop = True)\\\n",
    "                .reset_index()\n",
    "table = table.groupby(by = 'model')\\\n",
    "                .max()\\\n",
    "                .sort_values(by = 'index')\\\n",
    "                .drop('index', axis = 1)\n",
    "\n",
    "table['Correct prediction share'] = table['correct'].round(4)\n",
    "table['Validation MSE'] = (table['valMSE']*10**(2)).round(4)\n",
    "table['Test MSE'] = (table['testMSE']*10**(2)).round(4)\n",
    "table[['Correct prediction share', 'Validation MSE', 'Test MSE']].to_latex('models_compare.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predicting and plotting using the cross-validated Ridge model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get data from 2015\n",
    "data2015 = pd.read_csv('final_data2015.csv', index_col = 0).reset_index()\n",
    "data2015['left_share_norm'] = data2015['left_share']/(data2015['left_share']+data2015['right_share'])\n",
    "\n",
    "X2015 = data2015[['karakter', 'salgspris', 'disindk', 'kriminelitet', 'lavindk', 'langledig', 'skilsmisser', 'andel_indv', 'pop_density']]\n",
    "X2015[['salgspris_log', 'disindk_log', 'pop_density_log']] = np.log(X2015[['salgspris', 'disindk', 'pop_density']])\n",
    "X2015 = X2015.drop(['salgspris', 'disindk', 'pop_density'],axis = 1)\n",
    "\n",
    "y2015 = data2015['left_share_norm']\n",
    "\n",
    "\n",
    "# get data from 2019\n",
    "data2019 = pd.read_csv('final_data2019.csv', index_col = 0).reset_index()\n",
    "data2019['left_share_norm'] = data2019['left_share']/(data2019['left_share']+data2019['right_share'])\n",
    "\n",
    "X2019 = data2019[['karakter', 'salgspris', 'disindk', 'kriminelitet', 'lavindk', 'langledig', 'skilsmisser', 'andel_indv', 'pop_density']]\n",
    "X2019[['salgspris_log', 'disindk_log', 'pop_density_log']] = np.log(X2019[['salgspris', 'disindk', 'pop_density']])\n",
    "X2019 = X2019.drop(['salgspris', 'disindk', 'pop_density'],axis = 1)\n",
    "\n",
    "y2019 = data2019['left_share_norm']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit on 2015 and make predictions for 2015\n",
    "X_dev, X_test, y_dev, y_test = train_test_split(X2015, y2015, test_size = 1/3, random_state = 1)\n",
    "\n",
    "pipe_ridgeCV.fit(X_dev, y_dev)\n",
    "X2015_pred = pipe_ridgeCV.predict(X_test)\n",
    "X_test['prediction'] = X2015_pred\n",
    "X_test['left_majority_pred'] = (X_test['prediction'] >.5)*1\n",
    "X_test['left_majority'] = (y_test>.5)*1\n",
    "X_test['correct'] = (X_test['left_majority_pred'] == X_test['left_majority'])*1\n",
    "X_test['error'] = X_test['prediction'] - y_test\n",
    "\n",
    "# merge predictions to main dataset\n",
    "all2015 = pd.merge(left = data2015, right = X_test[['prediction', 'left_majority_pred', 'left_majority', 'correct','error']].reset_index(), on = 'index', how = 'outer' )\n",
    "all2015['test'] = (all2015['prediction'] > -100000)*1\n",
    "all2015['train'] = (all2015['test'] == 0)*1\n",
    "\n",
    "# merge to geometry\n",
    "geometry2015 = gpd.read_file('geometry2015.shp').rename(columns = {'id': 'index'})\n",
    "all2015 = pd.merge(left = all2015, right = geometry2015, on = 'index')\\\n",
    "            .set_geometry('geometry_y')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# develop 2019 data\n",
    "data2019['prediction'] = pipe_ridgeCV.predict(X2019)\n",
    "data2019['left_majority_pred'] = (data2019['prediction'] >.5)*1\n",
    "data2019['left_majority'] = (data2019['left_share_norm']>.5)*1\n",
    "data2019['correct'] = (data2019['left_majority_pred'] == data2019['left_majority'])*1\n",
    "data2019['error'] = data2019['prediction'] - data2019['left_share_norm']\n",
    "\n",
    "# merge to geometry\n",
    "geometry2019 = gpd.read_file('geometry2019.shp').rename(columns= {'id': 'index'})\n",
    "all2019 = pd.merge(left = data2019, right = geometry2019, on = 'index')\\\n",
    "            .set_geometry('geometry_y')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Prepare plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "data2019_dk = all2019[all2019['kommunekod'] != 400]\n",
    "data2019_bornholm = all2019[all2019['kommunekod'] == 400]\n",
    "data2015_dk = all2015[all2015['kommunekod'] != 400]\n",
    "data2015_bornholm = all2015[all2015['kommunekod'] == 400]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# recode predictions higher than 100 pct. or lower than 0 pct.\n",
    "def recode(n):\n",
    "    if n > 1:\n",
    "        return 1\n",
    "    if n < 0:\n",
    "        return 0\n",
    "    else:\n",
    "        return n\n",
    "\n",
    "for data in [data2019_dk, data2015_bornholm, data2015_dk, data2019_bornholm]:\n",
    "    data['prediction_v2'] = data['prediction'].apply(recode)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot errors "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with lolland\n",
    "fig, (ax1, ax2) = plt.subplots(1,2, figsize = (20,8))\n",
    "cmap = 'viridis'#'RdYlGn'\n",
    "\n",
    "vmin = min([all2019['error'].min(), all2015['error'].min()])\n",
    "vmax = max([all2019['error'].max(), all2015['error'].max()])\n",
    "\n",
    "data2015_dk.plot(column = 'train', ax = ax1, cmap = 'Greys', vmin = 0, vmax = 2)\n",
    "data2015_dk.plot( column = 'error', cmap = cmap, ax = ax1, vmin = vmin, vmax =vmax)\n",
    "ax1.set_axis_off()\n",
    "ax1.set_title('2015', size = 25)\n",
    "ax11 = plt.axes([0.315, 0.74, 0.12, 0.1])\n",
    "\n",
    "data2015_bornholm.plot(column = 'train', ax = ax11, cmap = 'Greys', vmin = 0, vmax = 2)\n",
    "data2015_bornholm.plot( column = 'error', cmap = cmap, ax = ax11, vmin = vmin, vmax =vmax)\n",
    "ax11.xaxis.set_visible(False)\n",
    "ax11.yaxis.set_visible(False)\n",
    "\n",
    "data2019_dk.plot( column = 'error', cmap = cmap, ax = ax2, vmin = vmin, vmax =vmax, legend = True)\n",
    "ax2.set_axis_off()\n",
    "ax2.set_title('2019', size = 25)\n",
    "\n",
    "ax21 = plt.axes([0.72, 0.74, 0.12, 0.1])\n",
    "data2019_bornholm.plot(column = 'error', cmap = cmap, ax = ax21, vmin = vmin, vmax =vmax)\n",
    "ax21.xaxis.set_visible(False)\n",
    "ax21.yaxis.set_visible(False)\n",
    "\n",
    "plt.savefig('errors.png')\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# without lolland\n",
    "fig, (ax1, ax2) = plt.subplots(1,2, figsize = (20,8))\n",
    "cmap = 'viridis'#'RdYlGn'\n",
    "\n",
    "vmin = min([all2019[all2019['kommunekod'] != 360]['error'].min(),\n",
    "           all2015[all2015['kommunekod'] != 360]['error'].min()])\n",
    "vmax = max([all2019[all2019['kommunekod'] != 360]['error'].max(),\n",
    "            all2015[all2019['kommunekod'] != 360]['error'].max()])\n",
    "\n",
    "data2015_dk.plot(column = 'train', ax = ax1, cmap = 'Greys', vmin = 0, vmax = 2)\n",
    "data2015_dk.plot( column = 'error', cmap = cmap, ax = ax1, vmin = vmin, vmax =vmax)\n",
    "ax1.set_axis_off()\n",
    "ax1.set_title('2015', size = 25)\n",
    "ax11 = plt.axes([0.315, 0.74, 0.12, 0.1])\n",
    "\n",
    "data2015_bornholm.plot(column = 'train', ax = ax11, cmap = 'Greys', vmin = 0, vmax = 2)\n",
    "data2015_bornholm.plot( column = 'error', cmap = cmap, ax = ax11, vmin = vmin, vmax =vmax)\n",
    "ax11.xaxis.set_visible(False)\n",
    "ax11.yaxis.set_visible(False)\n",
    "\n",
    "data2019_dk[data2019_dk['kommunekod'] != 360].plot( column = 'error', cmap = cmap, ax = ax2, vmin = vmin, vmax = vmax, legend = True)\n",
    "ax2.set_axis_off()\n",
    "ax2.set_title('2019', size = 25)\n",
    "\n",
    "ax21 = plt.axes([0.72, 0.74, 0.12, 0.1])\n",
    "data2019_bornholm.plot(column = 'error', cmap = cmap, ax = ax21, vmin = vmin, vmax =vmax)\n",
    "ax21.xaxis.set_visible(False)\n",
    "ax21.yaxis.set_visible(False)\n",
    "\n",
    "plt.savefig('errors_wo_lolland.png')\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, (ax1, ax2) = plt.subplots(1,2, figsize = (20,8))\n",
    "cmap = 'viridis'\n",
    "\n",
    "data2019_dk.plot(column = 'left_share_norm', vmin = 0, vmax = 1, cmap = cmap, ax = ax1)\n",
    "ax1.set_axis_off()\n",
    "ax1.set_title('Actual outcome', size = 25)\n",
    "ax11 = plt.axes([0.315, 0.74, 0.12, 0.1])\n",
    "\n",
    "data2019_bornholm.plot( column = 'left_share_norm', vmin = 0, vmax = 1, cmap = cmap, ax = ax11)\n",
    "ax11.xaxis.set_visible(False)\n",
    "ax11.yaxis.set_visible(False)\n",
    "\n",
    "data2019_dk.plot(column = 'prediction_v2', vmin = 0, vmax = 1, ax = ax2, cmap = cmap, legend = True)\n",
    "ax2.set_axis_off()\n",
    "ax2.set_title('Model prediction', size = 25)\n",
    "\n",
    "ax21 = plt.axes([0.72, 0.74, 0.12, 0.1])\n",
    "data2019_bornholm.plot(column = 'prediction_v2', vmin = 0, vmax = 1, ax = ax21, cmap = cmap)\n",
    "ax21.xaxis.set_visible(False)\n",
    "ax21.yaxis.set_visible(False)\n",
    "\n",
    "plt.savefig('prediction.png')\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot correct predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with lolland\n",
    "fig, (ax1, ax2) = plt.subplots(1,2, figsize = (20,8))\n",
    "cmap = 'RdYlGn'\n",
    "\n",
    "vmin = 0\n",
    "vmax = 1\n",
    "\n",
    "data2015_dk.plot(column = 'train', ax = ax1, cmap = 'Greys', vmin = 0, vmax = 2)\n",
    "data2015_dk.plot( column = 'correct', cmap = cmap, ax = ax1, vmin = vmin, vmax =vmax)\n",
    "ax1.set_axis_off()\n",
    "ax1.set_title('2015', size = 25)\n",
    "ax11 = plt.axes([0.315, 0.74, 0.12, 0.1])\n",
    "\n",
    "data2015_bornholm.plot(column = 'train', ax = ax11, cmap = 'Greys', vmin = 0, vmax = 2)\n",
    "data2015_bornholm.plot( column = 'correct', cmap = cmap, ax = ax11, vmin = vmin, vmax =vmax)\n",
    "ax11.xaxis.set_visible(False)\n",
    "ax11.yaxis.set_visible(False)\n",
    "\n",
    "data2019_dk.plot( column = 'correct', cmap = cmap, ax = ax2, vmin = vmin, vmax =vmax)\n",
    "ax2.set_axis_off()\n",
    "ax2.set_title('2019', size = 25)\n",
    "\n",
    "ax21 = plt.axes([0.72, 0.74, 0.12, 0.1])\n",
    "data2019_bornholm.plot(column = 'correct', cmap = cmap, ax = ax21, vmin = vmin, vmax =vmax)\n",
    "ax21.xaxis.set_visible(False)\n",
    "ax21.yaxis.set_visible(False)\n",
    "\n",
    "plt.savefig('correct.png')\n",
    "plt.close()"
   ]
  }
 ]
}